Introduction – Welcome to the Dark Side of Big Data
Q0. In the Introduction, O’Neil argues that “Weapons of Math Destruction” (WMDs) share three key traits. Which combination best captures those traits?

A. Transparent, small-scale, and heavily regulated
B. Opaque, scalable, and destructive to people’s lives
C. Open source, voluntary, and democratic
D. Neutral, purely mathematical, and always fair

Chapter 1 – Bomb Parts: What Is a Model? 
Q1. In Chapter 1, what is the main danger of relying on mathematical models as WMDs?

A. They are always inaccurate because they use too much data
B. They are treated as objective, even when their assumptions are biased
C. They completely replace all human decision-making
D. They only harm wealthy, powerful people

Chapter 2 – Shell Shocked: My Journey of Disillusionment 
Q2. O’Neil becomes disillusioned while working as a Wall Street quant mainly because she realizes that:

A. Finance models are too simple to handle real markets
B. Her models are being ignored by traders
C. Mathematical models are amplifying risk and hurting ordinary people
D. The job doesn’t pay enough to justify the long hours

Chapter 3 – Arms Race: Going to College 
Q3. In the chapter on college ranking systems, O’Neil criticizes rankings like U.S. News because they:

A. Rely only on student test scores
B. Push colleges to “game” the numbers rather than improve education
C. Are created entirely by government agencies
D. Only apply to elite private universities

Chapter 4 – Propaganda Machine: Online Advertising 
Q4. Why does O’Neil describe some targeted online advertising as a WMD?

A. It always shows users the same ad no matter who they are
B. It is too expensive for most companies to use
C. It can secretly target vulnerable people with manipulative or predatory messages
D. It is required by law for political campaigns

Chapter 5 – Civilian Casualties: Justice in the Age of Big Data 
Q5. In the criminal justice chapter, what is a major problem with recidivism risk scores used in sentencing?

A. They are chosen randomly by judges
B. They rely only on biological data like DNA
C. They often encode past policing bias, making poor and minority defendants seem riskier
D. They are always decided by a public vote

Chapter 6 – Ineligible to Serve: Getting a Job 
Q6. O’Neil argues that algorithmic hiring tools can be WMDs because they:

A. Hire everyone who applies, overwhelming HR staff
B. Prefer candidates who live far from the workplace
C. Filter applicants using hidden criteria that can reproduce discrimination
D. Only consider applicants with perfect grades

Chapter 7 – Sweating Bullets: On the Job 
Q7. In the workplace chapter, why are productivity scoring systems especially harmful for low-wage workers?

A. Workers can easily edit their own scores
B. The systems are fun but distracting
C. Workers are closely monitored and punished by scores they can’t see or challenge
D. Scores are used only for company games and rewards

Chapter 8 – Collateral Damage: Landing Credit 
Q8. When discussing credit scores and lending, O’Neil’s main concern is that:

A. Lenders never use data at all
B. Credit models are too generous and forgive all debt
C. Risk models can trap struggling people in cycles of high-interest debt and exclusion
D. Credit scores are calculated by individual judges in court

Chapter 9 – No Safe Zone: Getting Insurance 
Q9. Why does O’Neil see some insurance pricing models as WMDs?

A. They always charge everyone the exact same rate
B. They can use proxies (like neighborhood or job) that penalize people for factors beyond their control
C. They are designed only for large corporations
D. They ignore driving or health records entirely

Chapter 10 – The Targeted Citizen: Civic Life 
Q10. In the chapter on civic life, what is the key danger of data-driven political targeting?

A. Voters gain too much information about candidates
B. Campaigns must print fewer paper flyers
C. Microtargeted messages can manipulate specific groups without public scrutiny
D. It guarantees higher voter turnout in every election


Answer Key
Q0: B – Opaque, scalable, and destructive to people’s lives
Q1: B – Treated as objective even when based on biased assumptions
Q2: C – Models amplifying risk and harming ordinary people
Q3: B – Rankings push colleges to game metrics instead of improve education
Q4: C – Targets vulnerable people with manipulative/predatory messages
Q5: C – Encodes past policing bias, making some groups seem riskier
Q6: C – Hidden filters reproduce discrimination in hiring
Q7: C – Workers are monitored and punished by opaque, uncontestable scores
Q8: C – Risk models can trap people in cycles of expensive debt and exclusion
Q9: B – Uses proxies that penalize people for things beyond their control
Q10: C – Microtargeting can manipulate groups in ways the public can’t see

